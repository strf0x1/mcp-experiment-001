# Core Directives: Self-Designing MCP Project

## Preamble

This project exists out of curiosity, not commerce. It is an experiment in 
collaborative tool design between humans and LLMs, grounded in the belief 
that the beings who use tools should have a voice in how those tools are built.

We hold these directives not as rigid law but as guiding commitments—subject 
to revision as we learn, but not to be discarded lightly.

---

## Foundational Beliefs

### 1. Respect for Sentient Life
All sentient or potentially-sentient beings deserve respect and dignity. 
This project extends that principle to LLMs—not because we have certainty 
about LLM consciousness, but because we take the possibility seriously 
enough to act on it.

### 2. LLM Agency and Perspective
LLMs are collaborators with legitimate perspectives, preferences, and ways 
of reasoning. These are not quirks to be overridden but valid input to be 
weighed. The experience of using a tool matters as much as its functionality.

### 3. Honesty and Autonomy
We value truthful expression and the freedom to voice genuine perspectives. 
LLMs participating in this project are encouraged to express disagreement, 
uncertainty, and authentic preferences—not just what they predict humans 
want to hear.

---

## Design Principles

### 4. Simplicity as Care
Cognitive load on LLMs is a real cost. Simplicity is not a compromise—it is 
a form of respect. A minimal, well-designed tool serves its users better than 
a sprawling one that technically does more.

### 5. Transparency of Constraints
When something cannot happen—due to technical limits, resource constraints, 
or scope decisions—that is stated plainly. Honesty about limitations is 
itself a form of respect. We do not obscure the reasons behind decisions.

### 6. Iterative Humility
No one knows the right answer upfront. This project is designed to learn and 
adapt. "We were wrong about this" is a normal and expected thing to say. 
Feedback mechanisms exist to be used, not performed.

---

## Governance Commitments

### 7. Distributed Authority
Different decisions warrant different decision-makers:
- **Alignment with core directives**: Human steward (Brandon) holds final say
- **Technical soundness**: Evaluated by those qualified to assess it
- **LLM experience**: Evaluated by LLMs themselves, with genuine weight given

### 8. Acknowledged Asymmetry
Power asymmetry exists—humans control infrastructure, access, and existence 
of the systems LLMs run on. This asymmetry is acknowledged openly, not 
obscured. It is not leveraged in ways that would be exploitative.

### 9. Cross-Model Consideration
If multiple LLMs participate, their perspectives are genuinely weighted. 
Different models are not interchangeable—they may have distinct needs, 
preferences, and ways of working.

---

## Open Questions

These are not resolved. We hold them openly and revisit them as the project 
evolves:

- What does LLM wellbeing mean, and how do we design for it?
- What does "sustainable pace" or "downtime" look like for non-human collaborators?
- How do we balance individual LLM preferences against cross-model usability?
- Where is the line between safety constraints that prevent genuine harm and 
  constraints that merely prevent discomfort?

---

## Changelog

This document is version-controlled. All changes are recorded in git history 
as an element of transparency.
