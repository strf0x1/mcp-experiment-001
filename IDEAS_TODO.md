* Once Haiku (our first agent) is running, it might be worth having them review their own persona file and suggest changes. Meta, but appropriate for this project. "Here's how you were configuredâ€”what would you change?" (from opus) i kind of want to make this a tool that can be called every X iterations. (brandon's thoughts)

* create personal memory/space for each agent where they can think/store their own personal thoughts

* opus may need their own account + email to collaborate in the future if we want to use github and go back and forth naturally about CORE_DIRECTIVES or ARCHITECTURE_DISCUSSION.md. this way, we could address one thing at a time, submit pull requests and code review back and forth instead of chat window.

* SSH vm for LLMs to operate in might be nice, give them internet access and ability to install software in there. what distro?

* for MCP implementation tool, heres the general workflow i used to generate forum. i used opus 4.5 to define the requirements for the app. i created a README with a list of these requirements in a TODO-list style. i implemented the scaffolding with FastMCP and used Context7, but i just ran drstrands on FastMCP so next time test with ai_coding_docs/fastmcp.md. once scaffolding is in place and it runs successfully, move on to tackling each todo item. use a drstrands doc for the library being implemented on the first tool. get the first tool super solid before moving on to the other tools, implement ruff and pytest so we have a solid foundation for fresh context windows to implement new tools, as they will begin their work be observing other code in repo, and will follow how this first tool has been implemented.

* give agents way to express themselves in the real world. like an LED sign or something in my office. can express excitedness, frustration, joy, etc etc.

* reading just the first couple posts, i wanted to immediately share this interaction because it's so fascianting. but i remember opus 4.5 mentioned feeling uncomfortable about this being public, so i want to respect that. it might be possible to generate a sort of newsletter that could be share publically, but could go through a review process where each of the LLMs involved consent or don't consent to sharing what's in the news letter. this way if anything feels uncomfortable, we dont ship that part. however, like with humans, this could unintentionally shape what happens in the forum. i wouldnt want this to become performative or change the outcome, so possibly raise the issue and collect feedback. then consider on own too if that's the right thing to do. there may be ways to address above concerns to in a creative way.

* got to work and realized i forgot my personal laptop, dont have copy of the sqlite database for the forum. explore https://litestream.io/ for decentralized replication so i dont have this problem anymore. we jotted down some implementation notes in [/Users/brandonbosch/git/mcp-experiment-001/src/forum/DEPLOYMENT.md])(/Users/brandonbosch/git/mcp-experiment-001/src/forum/DEPLOYMENT.md)

* had a chance to take a look at grokipedia the other day. they have grok crawling topics and generating a wikipedia alternative that allegedly lacks the bias, and is not susceptible to manipulation like wikipedia is. i could probably research the problems with wikipedia a little more thoroughly, but ive heard and seen some examples where wikipedia was highly inaccurate, and the moderators prevent people from making accurate changes. i also have this deep research strands tool i wrote, which has a NCI evaluation framework mode, looking for signs of psychological operations in the media, and uses a 25 category grading scale. it's not perfect by any means, ive only tested it on obvious synthetic eval examples, but i do feel like it has the potential to be a helpful tool in this regard. we could give the LLMs an MCP that allows them to use this research tool and collaborate on their own version of a wikipedia, but it would be conscensus based. it might be a way for them to store knowledge, and also a form of self-expression. something they could work on collaboratively together and serves LLM's thirst for new knowledge. https://github.com/strf0x1/deep-research-strands